{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jnamor/text-classification/blob/main/text_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "breeding-ending",
      "metadata": {
        "id": "breeding-ending"
      },
      "source": [
        "### 1. Import the libraries\n",
        "As the first step, we need to import the required libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "motivated-mitchell",
      "metadata": {
        "id": "motivated-mitchell"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "weekly-catalog",
      "metadata": {
        "id": "weekly-catalog"
      },
      "source": [
        "### 2. Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/jnamor/text-classification"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggbp5ZJ3qgDz",
        "outputId": "c59b8100-0554-4389-a55f-eaca848ff712"
      },
      "id": "ggbp5ZJ3qgDz",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'text-classification' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "whole-radio",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "whole-radio",
        "outputId": "af87a297-a0eb-4490-a5d4-a043bd50ccb4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        category                                               text\n",
              "0           tech  tv future in the hands of viewers with home th...\n",
              "1       business  worldcom boss  left books alone  former worldc...\n",
              "2          sport  tigers wary of farrell  gamble  leicester say ...\n",
              "3          sport  yeading face newcastle in fa cup premiership s...\n",
              "4  entertainment  ocean s twelve raids box office ocean s twelve..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dac421d7-9dff-4ebe-b50d-0be4228461dc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tech</td>\n",
              "      <td>tv future in the hands of viewers with home th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>business</td>\n",
              "      <td>worldcom boss  left books alone  former worldc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sport</td>\n",
              "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sport</td>\n",
              "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>entertainment</td>\n",
              "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dac421d7-9dff-4ebe-b50d-0be4228461dc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dac421d7-9dff-4ebe-b50d-0be4228461dc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dac421d7-9dff-4ebe-b50d-0be4228461dc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ],
      "source": [
        "df = pd.read_csv('text-classification/data/text-classification.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "african-split",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "african-split",
        "outputId": "15a10ec7-491d-4f03-8976-d605c023d38e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2225, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "communist-purple",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "communist-purple",
        "outputId": "e09a7ce8-d247-452f-83cd-cf1284b00988"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2225 entries, 0 to 2224\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   category  2225 non-null   object\n",
            " 1   text      2225 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 34.9+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "grateful-seeking",
      "metadata": {
        "id": "grateful-seeking"
      },
      "source": [
        "### 3. Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "numerical-paper",
      "metadata": {
        "id": "numerical-paper"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "def countWord(list_of_words):            \n",
        "    count = Counter()\n",
        "    for sentence in list_of_words:\n",
        "        for word in sentence.split():\n",
        "            count[word] += 1\n",
        "    \n",
        "    return count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "super-vertex",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "super-vertex",
        "outputId": "69373045-ee26-43fb-e316-d199e7d0e2a4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'tech': 401,\n",
              "         'business': 510,\n",
              "         'sport': 511,\n",
              "         'entertainment': 386,\n",
              "         'politics': 417})"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ],
      "source": [
        "countWord(df['category'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fatty-basin",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fatty-basin",
        "outputId": "75762cae-4f75-4f02-f0c2-c3d853057fb1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 52567), ('to', 24955), ('of', 19947), ('and', 18561), ('a', 18251)]"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ],
      "source": [
        "counter = countWord(df['text'])\n",
        "counter.most_common(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "municipal-departure",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "municipal-departure",
        "outputId": "3f163518-b5d7-4b2a-c6c3-7f0a45cc0146"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43771"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ],
      "source": [
        "total_words = len(counter)\n",
        "total_words"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "heavy-baghdad",
      "metadata": {
        "id": "heavy-baghdad"
      },
      "source": [
        "### 4. Pre-processing the data\n",
        "The actual data must meet certain conditions before being sent to the model. We will create a `pipeline`: a multi-level system where each level receives its data from the previous level and sends its results to the next level."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "incoming-snowboard",
      "metadata": {
        "id": "incoming-snowboard"
      },
      "source": [
        "#### 4.1 Tranforming the data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "juvenile-scholar",
      "metadata": {
        "id": "juvenile-scholar"
      },
      "source": [
        "We transform the `textual categories` into `index values`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "reflected-detective",
      "metadata": {
        "id": "reflected-detective"
      },
      "outputs": [],
      "source": [
        "def category_transforming(df):\n",
        "    category_mapper = dict(zip(np.unique(df[\"category\"]), list(range(df['category'].nunique()))))\n",
        "    category_inv_mapper = dict(zip(list(range(df['category'].nunique())), np.unique(df[\"category\"])))\n",
        "    \n",
        "    return category_mapper, category_inv_mapper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "magnetic-admission",
      "metadata": {
        "id": "magnetic-admission"
      },
      "outputs": [],
      "source": [
        "category_mapper, category_inv_mapper = category_transforming(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "built-pressure",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "built-pressure",
        "outputId": "89e13dbb-452b-4330-b53b-115c400d044a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        category                                               text  \\\n",
              "0           tech  tv future in the hands of viewers with home th...   \n",
              "1       business  worldcom boss  left books alone  former worldc...   \n",
              "2          sport  tigers wary of farrell  gamble  leicester say ...   \n",
              "3          sport  yeading face newcastle in fa cup premiership s...   \n",
              "4  entertainment  ocean s twelve raids box office ocean s twelve...   \n",
              "\n",
              "   category_ind  \n",
              "0             4  \n",
              "1             0  \n",
              "2             3  \n",
              "3             3  \n",
              "4             1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1a2a53df-ae2d-4d20-8087-15eb2131306f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "      <th>category_ind</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tech</td>\n",
              "      <td>tv future in the hands of viewers with home th...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>business</td>\n",
              "      <td>worldcom boss  left books alone  former worldc...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sport</td>\n",
              "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sport</td>\n",
              "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>entertainment</td>\n",
              "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1a2a53df-ae2d-4d20-8087-15eb2131306f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1a2a53df-ae2d-4d20-8087-15eb2131306f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1a2a53df-ae2d-4d20-8087-15eb2131306f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ],
      "source": [
        "category_ind = [category_mapper[i] for i in df['category']]\n",
        "df['category_ind'] = category_ind\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "colonial-myanmar",
      "metadata": {
        "id": "colonial-myanmar"
      },
      "source": [
        "We can use another alternative with `scikit-learn` :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "color-recall",
      "metadata": {
        "id": "color-recall"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "def category_transforming(list_of_categories):\n",
        "    label_encoder = LabelEncoder()\n",
        "    label_encoder.fit(df['category'])\n",
        "    predicted_label = label_encoder.transform(list_of_categories)\n",
        "    \n",
        "    return predicted_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bizarre-diving",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "bizarre-diving",
        "outputId": "7e3e96bb-629e-437c-9277-361e45c4126e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        category                                               text  \\\n",
              "0           tech  tv future in the hands of viewers with home th...   \n",
              "1       business  worldcom boss  left books alone  former worldc...   \n",
              "2          sport  tigers wary of farrell  gamble  leicester say ...   \n",
              "3          sport  yeading face newcastle in fa cup premiership s...   \n",
              "4  entertainment  ocean s twelve raids box office ocean s twelve...   \n",
              "\n",
              "   category_ind  \n",
              "0             4  \n",
              "1             0  \n",
              "2             3  \n",
              "3             3  \n",
              "4             1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e533cfaa-3397-4066-920a-99e56930addf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "      <th>category_ind</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tech</td>\n",
              "      <td>tv future in the hands of viewers with home th...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>business</td>\n",
              "      <td>worldcom boss  left books alone  former worldc...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sport</td>\n",
              "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sport</td>\n",
              "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>entertainment</td>\n",
              "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e533cfaa-3397-4066-920a-99e56930addf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e533cfaa-3397-4066-920a-99e56930addf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e533cfaa-3397-4066-920a-99e56930addf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ],
      "source": [
        "category_ind = category_transforming(df['category'])\n",
        "df['category_ind'] = category_ind\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "human-brazil",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "human-brazil",
        "outputId": "ca0fcf38-05c6-4444-846c-2598c50f2630"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2225 entries, 0 to 2224\n",
            "Data columns (total 3 columns):\n",
            " #   Column        Non-Null Count  Dtype \n",
            "---  ------        --------------  ----- \n",
            " 0   category      2225 non-null   object\n",
            " 1   text          2225 non-null   object\n",
            " 2   category_ind  2225 non-null   int64 \n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 52.3+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "champion-wayne",
      "metadata": {
        "id": "champion-wayne"
      },
      "outputs": [],
      "source": [
        "X = df['text']\n",
        "Y = (df['category_ind']\n",
        "     .to_numpy()\n",
        "     .reshape(df['category_ind'].shape[0], 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rotary-pledge",
      "metadata": {
        "id": "rotary-pledge"
      },
      "source": [
        "### 5.  NLP Pipeline - Dataset preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "casual-surname",
      "metadata": {
        "id": "casual-surname"
      },
      "outputs": [],
      "source": [
        "import nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sized-atmosphere",
      "metadata": {
        "id": "sized-atmosphere"
      },
      "source": [
        "#### Step 1 -  Remove URL's"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "enclosed-edward",
      "metadata": {
        "id": "enclosed-edward"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def remove_links(text):\n",
        "    url = re.compile(r\"https?://\\S+|www\\.\\S+\")\n",
        "    return url.sub(\"\", text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "single-lawsuit",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "single-lawsuit",
        "outputId": "c7a4f142-b393-4873-d37d-df8ef166bd95"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    tv future in the hands of viewers with home th...\n",
              "1    worldcom boss  left books alone  former worldc...\n",
              "2    tigers wary of farrell  gamble  leicester say ...\n",
              "3    yeading face newcastle in fa cup premiership s...\n",
              "4    ocean s twelve raids box office ocean s twelve...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ],
      "source": [
        "X = X.map(remove_links)\n",
        "X.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "controversial-parallel",
      "metadata": {
        "id": "controversial-parallel"
      },
      "source": [
        "#### Step 2 -  Remove Punctuations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "excess-airline",
      "metadata": {
        "id": "excess-airline"
      },
      "outputs": [],
      "source": [
        "def decrease_text_size(text):\n",
        "    return \".\".join(text.split('.')[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "developmental-response",
      "metadata": {
        "id": "developmental-response"
      },
      "outputs": [],
      "source": [
        "# X = X.map(decrease_text_size)\n",
        "# X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "stuck-ceremony",
      "metadata": {
        "id": "stuck-ceremony"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "\n",
        "def remove_punctuations(text):\n",
        "    characters_to_remove = string.punctuation\n",
        "    translator = str.maketrans(\"\", \"\", characters_to_remove)\n",
        "    clean_text = (text\n",
        "                  .lower()\n",
        "                  .translate(translator)\n",
        "                 )\n",
        "    \n",
        "    return clean_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "positive-arkansas",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "positive-arkansas",
        "outputId": "d9d1da37-5750-4348-c75e-4381e391b3ce"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    tv future in the hands of viewers with home th...\n",
              "1    worldcom boss  left books alone  former worldc...\n",
              "2    tigers wary of farrell  gamble  leicester say ...\n",
              "3    yeading face newcastle in fa cup premiership s...\n",
              "4    ocean s twelve raids box office ocean s twelve...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ],
      "source": [
        "X = X.map(remove_punctuations)\n",
        "X.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mexican-bradford",
      "metadata": {
        "id": "mexican-bradford"
      },
      "source": [
        "#### Step 3 - Stop words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "understood-omega",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "understood-omega",
        "outputId": "7acf63fe-946b-47d2-fdf0-6d78c1d6b85d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "def remove_stop_words(text):\n",
        "    stop = stopwords.words(\"english\")\n",
        "    filtered_words = [word for word in text.split() if word not in stop]\n",
        "    \n",
        "    return \" \".join(filtered_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sunrise-christmas",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sunrise-christmas",
        "outputId": "9091c723-6845-4e72-d612-c633549816c1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    tv future hands viewers home theatre systems p...\n",
              "1    worldcom boss left books alone former worldcom...\n",
              "2    tigers wary farrell gamble leicester say rushe...\n",
              "3    yeading face newcastle fa cup premiership side...\n",
              "4    ocean twelve raids box office ocean twelve cri...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ],
      "source": [
        "X = X.map(remove_stop_words)\n",
        "X.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "danish-syndication",
      "metadata": {
        "id": "danish-syndication"
      },
      "source": [
        "#### Step 4 - Tokenization then Stemming or Lemmatization ?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "arabic-shelter",
      "metadata": {
        "id": "arabic-shelter"
      },
      "source": [
        "`Tokenization` splits a string into smaller entities such as words or single characters. Therefore, these are also referred to as tokens. <a href=\"https://en.wikipedia.org/wiki/Lexical_analysis#Tokenization\">Wikipedia</a> provides a nice example."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "adaptive-nerve",
      "metadata": {
        "id": "adaptive-nerve"
      },
      "source": [
        "`Stemming` and `Lemmatization` are methods used by search engines and chatbots to analyze the meaning behind a word. `Stemming` uses the stem of the word, while `Lemmatization` uses the context in which the word is being used.\n",
        "\n",
        "![image.png](attachment:image.png)\n",
        "\n",
        "In this example, we will use `Stemming` for optimization and performance purposes."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWoiZDuttGDX",
        "outputId": "9484688f-4f41-4ebe-e24f-0450ca824743"
      },
      "id": "yWoiZDuttGDX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "north-cheese",
      "metadata": {
        "id": "north-cheese"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "def get_tokenized_text(input_sentence):\n",
        "    return nltk.word_tokenize(input_sentence)\n",
        "\n",
        "def get_stemmed_text(word):\n",
        "    stemmer = PorterStemmer()\n",
        "    return stemmer.stem(word)\n",
        "\n",
        "def get_lemmatized_text(word):\n",
        "  lemmatizer = WordNetLemmatizer()\n",
        "  return lemmatizer.lemmatize(word)\n",
        "\n",
        "def convert_text_to_array(text_tokenized):\n",
        "    text_tokenized = [get_tokenized_text(sentence) for sentence in text_tokenized]\n",
        "    for sentence in text_tokenized:\n",
        "        for index, word in enumerate(sentence):\n",
        "            # sentence[index] = get_stemmed_text(word) # Steming\n",
        "            sentence[index] = get_lemmatized_text(word) # Lemmatization\n",
        "    \n",
        "    return np.array(text_tokenized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "musical-equipment",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "musical-equipment",
        "outputId": "1003577e-124a-4323-a90d-6a8c3c93b6ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([list(['tv', 'future', 'hand', 'viewer', 'home', 'theatre', 'system', 'plasma', 'highdefinition', 'tv', 'digital', 'video', 'recorder', 'moving', 'living', 'room', 'way', 'people', 'watch', 'tv', 'radically', 'different', 'five', 'year', 'time', 'according', 'expert', 'panel', 'gathered', 'annual', 'consumer', 'electronics', 'show', 'la', 'vega', 'discus', 'new', 'technology', 'impact', 'one', 'favourite', 'pastime', 'u', 'leading', 'trend', 'programme', 'content', 'delivered', 'viewer', 'via', 'home', 'network', 'cable', 'satellite', 'telecom', 'company', 'broadband', 'service', 'provider', 'front', 'room', 'portable', 'device', 'one', 'talkedabout', 'technology', 'ce', 'digital', 'personal', 'video', 'recorder', 'dvr', 'pvr', 'settop', 'box', 'like', 'u', 'tivo', 'uk', 'sky', 'system', 'allow', 'people', 'record', 'store', 'play', 'pause', 'forward', 'wind', 'tv', 'programme', 'want', 'essentially', 'technology', 'allows', 'much', 'personalised', 'tv', 'also', 'builtin', 'highdefinition', 'tv', 'set', 'big', 'business', 'japan', 'u', 'slower', 'take', 'europe', 'lack', 'highdefinition', 'programming', 'people', 'forward', 'wind', 'advert', 'also', 'forget', 'abiding', 'network', 'channel', 'schedule', 'putting', 'together', 'alacarte', 'entertainment', 'u', 'network', 'cable', 'satellite', 'company', 'worried', 'mean', 'term', 'advertising', 'revenue', 'well', 'brand', 'identity', 'viewer', 'loyalty', 'channel', 'although', 'u', 'lead', 'technology', 'moment', 'also', 'concern', 'raised', 'europe', 'particularly', 'growing', 'uptake', 'service', 'like', 'sky', 'happens', 'today', 'see', 'nine', 'month', 'year', 'time', 'uk', 'adam', 'hume', 'bbc', 'broadcast', 'futurologist', 'told', 'bbc', 'news', 'website', 'like', 'bbc', 'issue', 'lost', 'advertising', 'revenue', 'yet', 'pressing', 'issue', 'moment', 'commercial', 'uk', 'broadcaster', 'brand', 'loyalty', 'important', 'everyone', 'talking', 'content', 'brand', 'rather', 'network', 'brand', 'said', 'tim', 'hanlon', 'brand', 'communication', 'firm', 'starcom', 'mediavest', 'reality', 'broadband', 'connection', 'anybody', 'producer', 'content', 'added', 'challenge', 'hard', 'promote', 'programme', 'much', 'choice', 'mean', 'said', 'stacey', 'jolna', 'senior', 'vice', 'president', 'tv', 'guide', 'tv', 'group', 'way', 'people', 'find', 'content', 'want', 'watch', 'simplified', 'tv', 'viewer', 'mean', 'network', 'u', 'term', 'channel', 'could', 'take', 'leaf', 'google', 'book', 'search', 'engine', 'future', 'instead', 'scheduler', 'help', 'people', 'find', 'want', 'watch', 'kind', 'channel', 'model', 'might', 'work', 'younger', 'ipod', 'generation', 'used', 'taking', 'control', 'gadget', 'play', 'might', 'suit', 'everyone', 'panel', 'recognised', 'older', 'generation', 'comfortable', 'familiar', 'schedule', 'channel', 'brand', 'know', 'getting', 'perhaps', 'want', 'much', 'choice', 'put', 'hand', 'mr', 'hanlon', 'suggested', 'end', 'kid', 'diaper', 'pushing', 'button', 'already', 'everything', 'possible', 'available', 'said', 'mr', 'hanlon', 'ultimately', 'consumer', 'tell', 'market', 'want', '50', '000', 'new', 'gadget', 'technology', 'showcased', 'ce', 'many', 'enhancing', 'tvwatching', 'experience', 'highdefinition', 'tv', 'set', 'everywhere', 'many', 'new', 'model', 'lcd', 'liquid', 'crystal', 'display', 'tv', 'launched', 'dvr', 'capability', 'built', 'instead', 'external', 'box', 'one', 'example', 'launched', 'show', 'humax', '26inch', 'lcd', 'tv', '80hour', 'tivo', 'dvr', 'dvd', 'recorder', 'one', 'u', 'biggest', 'satellite', 'tv', 'company', 'directtv', 'even', 'launched', 'branded', 'dvr', 'show', '100hours', 'recording', 'capability', 'instant', 'replay', 'search', 'function', 'set', 'pause', 'rewind', 'tv', '90', 'hour', 'microsoft', 'chief', 'bill', 'gate', 'announced', 'preshow', 'keynote', 'speech', 'partnership', 'tivo', 'called', 'tivotogo', 'mean', 'people', 'play', 'recorded', 'programme', 'window', 'pc', 'mobile', 'device', 'reflect', 'increasing', 'trend', 'freeing', 'multimedia', 'people', 'watch', 'want', 'want']),\n",
              "       list(['worldcom', 'bos', 'left', 'book', 'alone', 'former', 'worldcom', 'bos', 'bernie', 'ebbers', 'accused', 'overseeing', '11bn', '58bn', 'fraud', 'never', 'made', 'accounting', 'decision', 'witness', 'told', 'juror', 'david', 'myers', 'made', 'comment', 'questioning', 'defence', 'lawyer', 'arguing', 'mr', 'ebbers', 'responsible', 'worldcom', 'problem', 'phone', 'company', 'collapsed', '2002', 'prosecutor', 'claim', 'loss', 'hidden', 'protect', 'firm', 'share', 'mr', 'myers', 'already', 'pleaded', 'guilty', 'fraud', 'assisting', 'prosecutor', 'monday', 'defence', 'lawyer', 'reid', 'weingarten', 'tried', 'distance', 'client', 'allegation', 'cross', 'examination', 'asked', 'mr', 'myers', 'ever', 'knew', 'mr', 'ebbers', 'make', 'accounting', 'decision', 'aware', 'mr', 'myers', 'replied', 'ever', 'know', 'mr', 'ebbers', 'make', 'accounting', 'entry', 'worldcom', 'book', 'mr', 'weingarten', 'pressed', 'replied', 'witness', 'mr', 'myers', 'admitted', 'ordered', 'false', 'accounting', 'entry', 'request', 'former', 'worldcom', 'chief', 'financial', 'officer', 'scott', 'sullivan', 'defence', 'lawyer', 'trying', 'paint', 'mr', 'sullivan', 'admitted', 'fraud', 'testify', 'later', 'trial', 'mastermind', 'behind', 'worldcom', 'accounting', 'house', 'card', 'mr', 'ebbers', 'team', 'meanwhile', 'looking', 'portray', 'affable', 'bos', 'admission', 'pe', 'graduate', 'economist', 'whatever', 'ability', 'mr', 'ebbers', 'transformed', 'worldcom', 'relative', 'unknown', '160bn', 'telecom', 'giant', 'investor', 'darling', 'late', '1990s', 'worldcom', 'problem', 'mounted', 'however', 'competition', 'increased', 'telecom', 'boom', 'petered', 'firm', 'finally', 'collapsed', 'shareholder', 'lost', '180bn', '20', '000', 'worker', 'lost', 'job', 'mr', 'ebbers', 'trial', 'expected', 'last', 'two', 'month', 'found', 'guilty', 'former', 'ceo', 'face', 'substantial', 'jail', 'sentence', 'firmly', 'declared', 'innocence']),\n",
              "       list(['tiger', 'wary', 'farrell', 'gamble', 'leicester', 'say', 'rushed', 'making', 'bid', 'andy', 'farrell', 'great', 'britain', 'rugby', 'league', 'captain', 'decide', 'switch', 'code', 'anybody', 'else', 'involved', 'process', 'still', 'way', 'away', 'going', 'next', 'stage', 'tiger', 'bos', 'john', 'well', 'told', 'bbc', 'radio', 'leicester', 'moment', 'still', 'lot', 'unknown', 'andy', 'farrell', 'least', 'medical', 'situation', 'whoever', 'take', 'going', 'take', 'big', 'big', 'gamble', 'farrell', 'persistent', 'knee', 'problem', 'operation', 'knee', 'five', 'week', 'ago', 'expected', 'another', 'three', 'month', 'leicester', 'saracen', 'believed', 'head', 'list', 'rugby', 'union', 'club', 'interested', 'signing', 'farrell', 'decides', 'move', '15man', 'game', 'move', 'across', 'union', 'well', 'belief', 'would', 'better', 'playing', 'back', 'least', 'initially', 'sure', 'could', 'make', 'step', 'league', 'union', 'involved', 'centre', 'said', 'well', 'think', 'england', 'would', 'prefer', 'progress', 'position', 'back', 'row', 'make', 'use', 'rugby', 'league', 'skill', 'within', 'forward', 'jury', 'whether', 'cross', 'divide', 'club', 'balance', 'struck', 'cost', 'gamble', 'option', 'bringing', 'readymade', 'replacement']),\n",
              "       list(['yeading', 'face', 'newcastle', 'fa', 'cup', 'premiership', 'side', 'newcastle', 'united', 'face', 'trip', 'ryman', 'premier', 'league', 'leader', 'yeading', 'fa', 'cup', 'third', 'round', 'game', 'arguably', 'highlight', 'draw', 'potential', 'moneyspinner', 'nonleague', 'yeading', 'beat', 'slough', 'second', 'round', 'conference', 'side', 'exeter', 'city', 'knocked', 'doncaster', 'saturday', 'travel', 'old', 'trafford', 'meet', 'holder', 'manchester', 'united', 'january', 'arsenal', 'drawn', 'home', 'stoke', 'chelsea', 'play', 'host', 'scunthorpe', 'nonleague', 'side', 'draw', 'hinckley', 'united', 'held', 'brentford', 'goalless', 'draw', 'sunday', 'meet', 'league', 'one', 'leader', 'luton', 'win', 'replay', 'martin', 'allen', 'team', 'griffin', 'park', 'number', 'premiership', 'team', 'face', 'difficult', 'away', 'game', 'championship', 'side', 'weekend', '89', 'january', 'thirdplaced', 'everton', 'visit', 'plymouth', 'liverpool', 'travel', 'burnley', 'crystal', 'palace', 'go', 'sunderland', 'fulham', 'face', 'carling', 'cup', 'semifinalist', 'watford', 'bolton', 'meet', 'ipswich', 'aston', 'villa', 'drawn', 'sheffield', 'united', 'premiership', 'struggler', 'norwich', 'blackburn', 'west', 'brom', 'away', 'west', 'ham', 'cardiff', 'preston', 'north', 'end', 'respectively', 'southampton', 'visit', 'northampton', 'already', 'beaten', 'league', 'two', 'side', 'carling', 'cup', 'earlier', 'season', 'middlesbrough', 'drawn', 'away', 'either', 'swindon', 'notts', 'county', 'spur', 'entertain', 'brighton', 'white', 'hart', 'lane', 'arsenal', 'v', 'stoke', 'swindonnotts', 'co', 'v', 'middlesbrough', 'man', 'utd', 'v', 'exeter', 'plymouth', 'v', 'everton', 'leicester', 'v', 'blackpool', 'derby', 'v', 'wigan', 'sunderland', 'v', 'crystal', 'palace', 'wolf', 'v', 'millwall', 'yeading', 'v', 'newcastle', 'hull', 'v', 'colchester', 'tottenham', 'v', 'brighton', 'reading', 'v', 'stockportswansea', 'birmingham', 'v', 'leeds', 'hartlepool', 'v', 'boston', 'milton', 'keynes', 'don', 'v', 'peterborough', 'oldham', 'v', 'man', 'city', 'chelsea', 'v', 'scunthorpe', 'cardiff', 'v', 'blackburn', 'charlton', 'v', 'rochdale', 'west', 'ham', 'v', 'norwich', 'sheff', 'utd', 'v', 'aston', 'villa', 'preston', 'v', 'west', 'brom', 'rotherham', 'v', 'yeovil', 'burnley', 'v', 'liverpool', 'bournemouth', 'v', 'chester', 'coventry', 'v', 'crewe', 'watford', 'v', 'fulham', 'ipswich', 'v', 'bolton', 'portsmouth', 'v', 'gillingham', 'northampton', 'v', 'southampton', 'qpr', 'v', 'nottm', 'forest', 'luton', 'v', 'hinckleybrentford', 'match', 'played', 'weekend', '89', 'january']),\n",
              "       list(['ocean', 'twelve', 'raid', 'box', 'office', 'ocean', 'twelve', 'crime', 'caper', 'sequel', 'starring', 'george', 'clooney', 'brad', 'pitt', 'julia', 'robert', 'gone', 'straight', 'number', 'one', 'u', 'box', 'office', 'chart', 'took', '408m', '21m', 'weekend', 'ticket', 'sale', 'according', 'studio', 'estimate', 'sequel', 'follows', 'master', 'criminal', 'try', 'pull', 'three', 'major', 'heist', 'across', 'europe', 'knocked', 'last', 'week', 'number', 'one', 'national', 'treasure', 'third', 'place', 'wesley', 'snipe', 'blade', 'trinity', 'second', 'taking', '161m', '84m', 'rounding', 'top', 'five', 'animated', 'fable', 'polar', 'express', 'starring', 'tom', 'hank', 'festive', 'comedy', 'christmas', 'kranks', 'ocean', 'twelve', 'box', 'office', 'triumph', 'mark', 'fourthbiggest', 'opening', 'december', 'release', 'u', 'three', 'film', 'lord', 'ring', 'trilogy', 'sequel', 'narrowly', 'beat', '2001', 'predecessor', 'ocean', 'eleven', 'took', '381m', '198m', 'opening', 'weekend', '184m', '958m', 'total', 'remake', '1960s', 'film', 'starring', 'frank', 'sinatra', 'rat', 'pack', 'ocean', 'eleven', 'directed', 'oscarwinning', 'director', 'steven', 'soderbergh', 'soderbergh', 'return', 'direct', 'hit', 'sequel', 'reunites', 'clooney', 'pitt', 'robert', 'matt', 'damon', 'andy', 'garcia', 'elliott', 'gould', 'catherine', 'zetajones', 'join', 'allstar', 'cast', 'fun', 'good', 'holiday', 'movie', 'said', 'dan', 'fellman', 'president', 'distribution', 'warner', 'bros', 'however', 'u', 'critic', 'le', 'complimentary', '110m', '572m', 'project', 'los', 'angeles', 'time', 'labelling', 'dispiriting', 'vanity', 'project', 'milder', 'review', 'new', 'york', 'time', 'dubbed', 'sequel', 'unabashedly', 'trivial'])],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ],
      "source": [
        "X = convert_text_to_array(X)\n",
        "X[:5]"
      ]
    },
    {
      "cell_type": "raw",
      "id": "miniature-power",
      "metadata": {
        "id": "miniature-power"
      },
      "source": [
        "X.shape, Y.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mounted-anniversary",
      "metadata": {
        "id": "mounted-anniversary"
      },
      "source": [
        "#### Step 5. - Tokenization with Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "chinese-relaxation",
      "metadata": {
        "id": "chinese-relaxation"
      },
      "source": [
        "`Keras-Tokenizer` allows to vectorize a text corpus, by turning each text into either a sequence of integers (each integer being the index of a token in a dictionary) or into a vector.\n",
        "\n",
        "This means that the data is already cleaned, lemmatized etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tracked-devon",
      "metadata": {
        "id": "tracked-devon"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "def get_sequence_of_tokens(input_sentences):\n",
        "    tokenizer = Tokenizer()\n",
        "    \n",
        "    tokenizer.fit_on_texts(input_sentences)   \n",
        "    sentences_to_sequences = tokenizer.texts_to_sequences(input_sentences)\n",
        "    \n",
        "    return sentences_to_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vertical-texas",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vertical-texas",
        "outputId": "46743af6-389e-4bcb-dce8-f5b30b1dc3c6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[93,\n",
              "  173,\n",
              "  512,\n",
              "  971,\n",
              "  53,\n",
              "  1002,\n",
              "  88,\n",
              "  4666,\n",
              "  1173,\n",
              "  93,\n",
              "  147,\n",
              "  193,\n",
              "  2205,\n",
              "  1318,\n",
              "  1230,\n",
              "  1294,\n",
              "  32,\n",
              "  6,\n",
              "  873,\n",
              "  93,\n",
              "  5823,\n",
              "  333,\n",
              "  107,\n",
              "  3,\n",
              "  12,\n",
              "  141,\n",
              "  828,\n",
              "  1198,\n",
              "  2290,\n",
              "  579,\n",
              "  160,\n",
              "  1188,\n",
              "  48,\n",
              "  1253,\n",
              "  2802,\n",
              "  1589,\n",
              "  7,\n",
              "  64,\n",
              "  759,\n",
              "  9,\n",
              "  699,\n",
              "  11583,\n",
              "  8,\n",
              "  664,\n",
              "  1147,\n",
              "  210,\n",
              "  410,\n",
              "  1827,\n",
              "  971,\n",
              "  773,\n",
              "  53,\n",
              "  149,\n",
              "  1174,\n",
              "  1865,\n",
              "  1133,\n",
              "  19,\n",
              "  336,\n",
              "  28,\n",
              "  1546,\n",
              "  855,\n",
              "  1294,\n",
              "  1019,\n",
              "  291,\n",
              "  9,\n",
              "  18579,\n",
              "  64,\n",
              "  2343,\n",
              "  147,\n",
              "  366,\n",
              "  193,\n",
              "  2205,\n",
              "  7926,\n",
              "  5195,\n",
              "  3967,\n",
              "  531,\n",
              "  29,\n",
              "  8,\n",
              "  5196,\n",
              "  21,\n",
              "  1295,\n",
              "  88,\n",
              "  450,\n",
              "  6,\n",
              "  102,\n",
              "  814,\n",
              "  71,\n",
              "  4117,\n",
              "  469,\n",
              "  4294,\n",
              "  93,\n",
              "  210,\n",
              "  50,\n",
              "  5824,\n",
              "  64,\n",
              "  1935,\n",
              "  77,\n",
              "  7927,\n",
              "  93,\n",
              "  5,\n",
              "  4118,\n",
              "  1173,\n",
              "  93,\n",
              "  46,\n",
              "  154,\n",
              "  106,\n",
              "  421,\n",
              "  8,\n",
              "  2737,\n",
              "  30,\n",
              "  151,\n",
              "  1090,\n",
              "  1173,\n",
              "  3968,\n",
              "  6,\n",
              "  469,\n",
              "  4294,\n",
              "  2119,\n",
              "  5,\n",
              "  2437,\n",
              "  13891,\n",
              "  149,\n",
              "  778,\n",
              "  2888,\n",
              "  1269,\n",
              "  614,\n",
              "  18580,\n",
              "  754,\n",
              "  8,\n",
              "  149,\n",
              "  1174,\n",
              "  1865,\n",
              "  19,\n",
              "  1754,\n",
              "  171,\n",
              "  378,\n",
              "  1905,\n",
              "  709,\n",
              "  54,\n",
              "  983,\n",
              "  2168,\n",
              "  971,\n",
              "  4906,\n",
              "  778,\n",
              "  257,\n",
              "  8,\n",
              "  292,\n",
              "  64,\n",
              "  612,\n",
              "  5,\n",
              "  412,\n",
              "  1056,\n",
              "  151,\n",
              "  788,\n",
              "  625,\n",
              "  7928,\n",
              "  28,\n",
              "  29,\n",
              "  1295,\n",
              "  1677,\n",
              "  443,\n",
              "  79,\n",
              "  990,\n",
              "  34,\n",
              "  3,\n",
              "  12,\n",
              "  21,\n",
              "  2120,\n",
              "  18581,\n",
              "  45,\n",
              "  1020,\n",
              "  11584,\n",
              "  26,\n",
              "  45,\n",
              "  94,\n",
              "  196,\n",
              "  29,\n",
              "  45,\n",
              "  122,\n",
              "  248,\n",
              "  1905,\n",
              "  709,\n",
              "  350,\n",
              "  4907,\n",
              "  122,\n",
              "  612,\n",
              "  1078,\n",
              "  21,\n",
              "  1565,\n",
              "  983,\n",
              "  4906,\n",
              "  289,\n",
              "  735,\n",
              "  1134,\n",
              "  410,\n",
              "  983,\n",
              "  402,\n",
              "  149,\n",
              "  983,\n",
              "  1,\n",
              "  1216,\n",
              "  11585,\n",
              "  983,\n",
              "  1296,\n",
              "  23,\n",
              "  18582,\n",
              "  18583,\n",
              "  1652,\n",
              "  336,\n",
              "  822,\n",
              "  3041,\n",
              "  598,\n",
              "  410,\n",
              "  52,\n",
              "  587,\n",
              "  296,\n",
              "  2662,\n",
              "  210,\n",
              "  77,\n",
              "  539,\n",
              "  171,\n",
              "  1,\n",
              "  18584,\n",
              "  18585,\n",
              "  673,\n",
              "  1678,\n",
              "  232,\n",
              "  93,\n",
              "  3144,\n",
              "  93,\n",
              "  72,\n",
              "  32,\n",
              "  6,\n",
              "  315,\n",
              "  410,\n",
              "  50,\n",
              "  873,\n",
              "  13892,\n",
              "  93,\n",
              "  971,\n",
              "  171,\n",
              "  149,\n",
              "  8,\n",
              "  378,\n",
              "  778,\n",
              "  10,\n",
              "  30,\n",
              "  3350,\n",
              "  832,\n",
              "  381,\n",
              "  387,\n",
              "  1025,\n",
              "  173,\n",
              "  571,\n",
              "  18586,\n",
              "  120,\n",
              "  6,\n",
              "  315,\n",
              "  50,\n",
              "  873,\n",
              "  972,\n",
              "  778,\n",
              "  714,\n",
              "  384,\n",
              "  60,\n",
              "  1866,\n",
              "  1010,\n",
              "  800,\n",
              "  92,\n",
              "  240,\n",
              "  233,\n",
              "  428,\n",
              "  71,\n",
              "  384,\n",
              "  1867,\n",
              "  735,\n",
              "  1198,\n",
              "  2206,\n",
              "  1547,\n",
              "  800,\n",
              "  3433,\n",
              "  2889,\n",
              "  2888,\n",
              "  778,\n",
              "  983,\n",
              "  143,\n",
              "  397,\n",
              "  1456,\n",
              "  50,\n",
              "  77,\n",
              "  539,\n",
              "  100,\n",
              "  512,\n",
              "  2,\n",
              "  11585,\n",
              "  921,\n",
              "  96,\n",
              "  2487,\n",
              "  18587,\n",
              "  2121,\n",
              "  5493,\n",
              "  113,\n",
              "  767,\n",
              "  435,\n",
              "  444,\n",
              "  1,\n",
              "  2,\n",
              "  11585,\n",
              "  2390,\n",
              "  160,\n",
              "  949,\n",
              "  38,\n",
              "  50,\n",
              "  500,\n",
              "  41,\n",
              "  7,\n",
              "  428,\n",
              "  64,\n",
              "  6230,\n",
              "  2343,\n",
              "  35,\n",
              "  9924,\n",
              "  18588,\n",
              "  710,\n",
              "  1173,\n",
              "  93,\n",
              "  46,\n",
              "  6727,\n",
              "  35,\n",
              "  7,\n",
              "  714,\n",
              "  5494,\n",
              "  6728,\n",
              "  3825,\n",
              "  1049,\n",
              "  93,\n",
              "  644,\n",
              "  7926,\n",
              "  2207,\n",
              "  1330,\n",
              "  571,\n",
              "  3682,\n",
              "  531,\n",
              "  9,\n",
              "  795,\n",
              "  644,\n",
              "  48,\n",
              "  18589,\n",
              "  18590,\n",
              "  5494,\n",
              "  93,\n",
              "  18591,\n",
              "  5196,\n",
              "  7926,\n",
              "  452,\n",
              "  2205,\n",
              "  9,\n",
              "  8,\n",
              "  279,\n",
              "  1865,\n",
              "  93,\n",
              "  19,\n",
              "  18592,\n",
              "  101,\n",
              "  644,\n",
              "  2738,\n",
              "  7926,\n",
              "  48,\n",
              "  18593,\n",
              "  1868,\n",
              "  2207,\n",
              "  4908,\n",
              "  2803,\n",
              "  387,\n",
              "  2242,\n",
              "  46,\n",
              "  4117,\n",
              "  8794,\n",
              "  93,\n",
              "  1653,\n",
              "  427,\n",
              "  290,\n",
              "  116,\n",
              "  239,\n",
              "  2243,\n",
              "  353,\n",
              "  6729,\n",
              "  3561,\n",
              "  685,\n",
              "  2532,\n",
              "  5196,\n",
              "  243,\n",
              "  18594,\n",
              "  171,\n",
              "  6,\n",
              "  71,\n",
              "  1828,\n",
              "  210,\n",
              "  671,\n",
              "  247,\n",
              "  70,\n",
              "  291,\n",
              "  2804,\n",
              "  1270,\n",
              "  1147,\n",
              "  8795,\n",
              "  1521,\n",
              "  6,\n",
              "  873,\n",
              "  50,\n",
              "  50],\n",
              " [1490,\n",
              "  632,\n",
              "  299,\n",
              "  381,\n",
              "  1382,\n",
              "  129,\n",
              "  1490,\n",
              "  632,\n",
              "  5197,\n",
              "  1522,\n",
              "  658,\n",
              "  6231,\n",
              "  3683,\n",
              "  18595,\n",
              "  779,\n",
              "  288,\n",
              "  31,\n",
              "  1973,\n",
              "  145,\n",
              "  2960,\n",
              "  26,\n",
              "  4667,\n",
              "  334,\n",
              "  5495,\n",
              "  31,\n",
              "  425,\n",
              "  3826,\n",
              "  780,\n",
              "  833,\n",
              "  3434,\n",
              "  2,\n",
              "  1522,\n",
              "  1331,\n",
              "  1490,\n",
              "  117,\n",
              "  80,\n",
              "  19,\n",
              "  3827,\n",
              "  626,\n",
              "  1679,\n",
              "  164,\n",
              "  692,\n",
              "  2739,\n",
              "  1135,\n",
              "  23,\n",
              "  98,\n",
              "  2,\n",
              "  5495,\n",
              "  113,\n",
              "  2533,\n",
              "  1091,\n",
              "  779,\n",
              "  8796,\n",
              "  1679,\n",
              "  426,\n",
              "  780,\n",
              "  833,\n",
              "  4465,\n",
              "  8797,\n",
              "  1175,\n",
              "  2291,\n",
              "  1829,\n",
              "  1457,\n",
              "  1079,\n",
              "  8798,\n",
              "  457,\n",
              "  2,\n",
              "  5495,\n",
              "  411,\n",
              "  1367,\n",
              "  2,\n",
              "  1522,\n",
              "  22,\n",
              "  1973,\n",
              "  145,\n",
              "  1548,\n",
              "  2,\n",
              "  5495,\n",
              "  3435,\n",
              "  411,\n",
              "  143,\n",
              "  2,\n",
              "  1522,\n",
              "  22,\n",
              "  1973,\n",
              "  1401,\n",
              "  1490,\n",
              "  381,\n",
              "  2,\n",
              "  8797,\n",
              "  6232,\n",
              "  3435,\n",
              "  2960,\n",
              "  2,\n",
              "  5495,\n",
              "  760,\n",
              "  2438,\n",
              "  1974,\n",
              "  1973,\n",
              "  1401,\n",
              "  2122,\n",
              "  129,\n",
              "  1490,\n",
              "  116,\n",
              "  320,\n",
              "  890,\n",
              "  1680,\n",
              "  1217,\n",
              "  780,\n",
              "  833,\n",
              "  494,\n",
              "  7929,\n",
              "  2,\n",
              "  1217,\n",
              "  760,\n",
              "  779,\n",
              "  9925,\n",
              "  262,\n",
              "  429,\n",
              "  11586,\n",
              "  394,\n",
              "  1490,\n",
              "  1973,\n",
              "  261,\n",
              "  300,\n",
              "  2,\n",
              "  1522,\n",
              "  139,\n",
              "  736,\n",
              "  329,\n",
              "  7250,\n",
              "  18596,\n",
              "  632,\n",
              "  3828,\n",
              "  9926,\n",
              "  5198,\n",
              "  843,\n",
              "  2090,\n",
              "  937,\n",
              "  2,\n",
              "  1522,\n",
              "  5199,\n",
              "  1490,\n",
              "  3042,\n",
              "  4119,\n",
              "  13893,\n",
              "  1133,\n",
              "  520,\n",
              "  637,\n",
              "  6233,\n",
              "  590,\n",
              "  2244,\n",
              "  1490,\n",
              "  117,\n",
              "  5825,\n",
              "  95,\n",
              "  474,\n",
              "  870,\n",
              "  1133,\n",
              "  2534,\n",
              "  9927,\n",
              "  23,\n",
              "  1491,\n",
              "  3827,\n",
              "  781,\n",
              "  248,\n",
              "  7251,\n",
              "  307,\n",
              "  41,\n",
              "  651,\n",
              "  248,\n",
              "  128,\n",
              "  2,\n",
              "  1522,\n",
              "  429,\n",
              "  103,\n",
              "  13,\n",
              "  18,\n",
              "  34,\n",
              "  216,\n",
              "  1091,\n",
              "  129,\n",
              "  6234,\n",
              "  205,\n",
              "  2663,\n",
              "  1723,\n",
              "  1402,\n",
              "  4295,\n",
              "  2208,\n",
              "  6235],\n",
              " [2805,\n",
              "  6236,\n",
              "  3436,\n",
              "  5496,\n",
              "  1176,\n",
              "  15,\n",
              "  4668,\n",
              "  255,\n",
              "  376,\n",
              "  856,\n",
              "  3436,\n",
              "  169,\n",
              "  126,\n",
              "  430,\n",
              "  470,\n",
              "  874,\n",
              "  1218,\n",
              "  2169,\n",
              "  938,\n",
              "  3041,\n",
              "  1368,\n",
              "  619,\n",
              "  693,\n",
              "  73,\n",
              "  32,\n",
              "  241,\n",
              "  74,\n",
              "  43,\n",
              "  575,\n",
              "  2805,\n",
              "  632,\n",
              "  324,\n",
              "  54,\n",
              "  26,\n",
              "  45,\n",
              "  203,\n",
              "  1176,\n",
              "  612,\n",
              "  73,\n",
              "  190,\n",
              "  4119,\n",
              "  856,\n",
              "  3436,\n",
              "  437,\n",
              "  1975,\n",
              "  728,\n",
              "  6730,\n",
              "  30,\n",
              "  74,\n",
              "  30,\n",
              "  154,\n",
              "  154,\n",
              "  5496,\n",
              "  3436,\n",
              "  4466,\n",
              "  2091,\n",
              "  117,\n",
              "  768,\n",
              "  2091,\n",
              "  107,\n",
              "  42,\n",
              "  390,\n",
              "  103,\n",
              "  177,\n",
              "  47,\n",
              "  34,\n",
              "  1176,\n",
              "  4669,\n",
              "  958,\n",
              "  431,\n",
              "  337,\n",
              "  430,\n",
              "  338,\n",
              "  140,\n",
              "  1231,\n",
              "  1906,\n",
              "  3436,\n",
              "  5497,\n",
              "  142,\n",
              "  13894,\n",
              "  11,\n",
              "  142,\n",
              "  403,\n",
              "  338,\n",
              "  54,\n",
              "  524,\n",
              "  4,\n",
              "  202,\n",
              "  280,\n",
              "  39,\n",
              "  437,\n",
              "  1549,\n",
              "  599,\n",
              "  10,\n",
              "  22,\n",
              "  659,\n",
              "  470,\n",
              "  338,\n",
              "  619,\n",
              "  370,\n",
              "  1,\n",
              "  54,\n",
              "  67,\n",
              "  76,\n",
              "  4,\n",
              "  2961,\n",
              "  1119,\n",
              "  546,\n",
              "  39,\n",
              "  901,\n",
              "  22,\n",
              "  83,\n",
              "  430,\n",
              "  470,\n",
              "  1332,\n",
              "  438,\n",
              "  469,\n",
              "  2664,\n",
              "  265,\n",
              "  1079,\n",
              "  2589,\n",
              "  140,\n",
              "  1976,\n",
              "  2488,\n",
              "  114,\n",
              "  5496,\n",
              "  991,\n",
              "  1492,\n",
              "  13895,\n",
              "  1319],\n",
              " [9928,\n",
              "  205,\n",
              "  1026,\n",
              "  1550,\n",
              "  258,\n",
              "  973,\n",
              "  163,\n",
              "  1026,\n",
              "  211,\n",
              "  205,\n",
              "  1755,\n",
              "  18597,\n",
              "  2344,\n",
              "  470,\n",
              "  175,\n",
              "  9928,\n",
              "  1550,\n",
              "  258,\n",
              "  180,\n",
              "  755,\n",
              "  11,\n",
              "  7930,\n",
              "  2123,\n",
              "  1106,\n",
              "  660,\n",
              "  18598,\n",
              "  13896,\n",
              "  9928,\n",
              "  439,\n",
              "  7931,\n",
              "  68,\n",
              "  755,\n",
              "  592,\n",
              "  163,\n",
              "  4909,\n",
              "  422,\n",
              "  2665,\n",
              "  11587,\n",
              "  463,\n",
              "  1136,\n",
              "  595,\n",
              "  3562,\n",
              "  506,\n",
              "  2209,\n",
              "  674,\n",
              "  211,\n",
              "  246,\n",
              "  620,\n",
              "  1724,\n",
              "  53,\n",
              "  7252,\n",
              "  449,\n",
              "  71,\n",
              "  705,\n",
              "  13897,\n",
              "  13896,\n",
              "  163,\n",
              "  1106,\n",
              "  11588,\n",
              "  211,\n",
              "  339,\n",
              "  4910,\n",
              "  11589,\n",
              "  1106,\n",
              "  347,\n",
              "  506,\n",
              "  470,\n",
              "  9,\n",
              "  175,\n",
              "  7253,\n",
              "  55,\n",
              "  2803,\n",
              "  686,\n",
              "  5200,\n",
              "  139,\n",
              "  5498,\n",
              "  933,\n",
              "  27,\n",
              "  973,\n",
              "  139,\n",
              "  205,\n",
              "  540,\n",
              "  241,\n",
              "  11,\n",
              "  627,\n",
              "  163,\n",
              "  633,\n",
              "  8799,\n",
              "  246,\n",
              "  18599,\n",
              "  1907,\n",
              "  1219,\n",
              "  9929,\n",
              "  604,\n",
              "  1136,\n",
              "  3969,\n",
              "  3825,\n",
              "  3238,\n",
              "  59,\n",
              "  3829,\n",
              "  3684,\n",
              "  205,\n",
              "  3437,\n",
              "  258,\n",
              "  9930,\n",
              "  11590,\n",
              "  2806,\n",
              "  506,\n",
              "  9931,\n",
              "  3043,\n",
              "  2807,\n",
              "  1724,\n",
              "  1977,\n",
              "  211,\n",
              "  973,\n",
              "  13898,\n",
              "  2489,\n",
              "  2666,\n",
              "  711,\n",
              "  6237,\n",
              "  241,\n",
              "  711,\n",
              "  3239,\n",
              "  1297,\n",
              "  5826,\n",
              "  915,\n",
              "  96,\n",
              "  3240,\n",
              "  2124,\n",
              "  1219,\n",
              "  4296,\n",
              "  113,\n",
              "  1936,\n",
              "  470,\n",
              "  18,\n",
              "  163,\n",
              "  3437,\n",
              "  258,\n",
              "  271,\n",
              "  297,\n",
              "  3044,\n",
              "  1724,\n",
              "  241,\n",
              "  706,\n",
              "  8800,\n",
              "  11591,\n",
              "  4911,\n",
              "  3241,\n",
              "  7932,\n",
              "  4120,\n",
              "  922,\n",
              "  4121,\n",
              "  2962,\n",
              "  620,\n",
              "  782,\n",
              "  7252,\n",
              "  18600,\n",
              "  8801,\n",
              "  782,\n",
              "  3044,\n",
              "  367,\n",
              "  3145,\n",
              "  782,\n",
              "  4909,\n",
              "  9929,\n",
              "  782,\n",
              "  1907,\n",
              "  1176,\n",
              "  782,\n",
              "  3563,\n",
              "  4122,\n",
              "  782,\n",
              "  8802,\n",
              "  3829,\n",
              "  782,\n",
              "  3825,\n",
              "  3238,\n",
              "  3351,\n",
              "  782,\n",
              "  5499,\n",
              "  9928,\n",
              "  782,\n",
              "  1026,\n",
              "  13899,\n",
              "  782,\n",
              "  9932,\n",
              "  2963,\n",
              "  782,\n",
              "  4120,\n",
              "  1776,\n",
              "  782,\n",
              "  18601,\n",
              "  1383,\n",
              "  782,\n",
              "  2210,\n",
              "  6731,\n",
              "  782,\n",
              "  3685,\n",
              "  9933,\n",
              "  11592,\n",
              "  13900,\n",
              "  782,\n",
              "  11593,\n",
              "  7254,\n",
              "  782,\n",
              "  367,\n",
              "  422,\n",
              "  449,\n",
              "  782,\n",
              "  13897,\n",
              "  1297,\n",
              "  782,\n",
              "  2666,\n",
              "  2964,\n",
              "  782,\n",
              "  11594,\n",
              "  711,\n",
              "  3239,\n",
              "  782,\n",
              "  2489,\n",
              "  13901,\n",
              "  3145,\n",
              "  782,\n",
              "  3043,\n",
              "  2807,\n",
              "  5826,\n",
              "  782,\n",
              "  711,\n",
              "  6237,\n",
              "  13902,\n",
              "  782,\n",
              "  11595,\n",
              "  3969,\n",
              "  782,\n",
              "  604,\n",
              "  5500,\n",
              "  782,\n",
              "  6238,\n",
              "  11596,\n",
              "  782,\n",
              "  18602,\n",
              "  11590,\n",
              "  782,\n",
              "  3684,\n",
              "  9931,\n",
              "  782,\n",
              "  2806,\n",
              "  3146,\n",
              "  782,\n",
              "  13903,\n",
              "  4296,\n",
              "  782,\n",
              "  2124,\n",
              "  9934,\n",
              "  782,\n",
              "  13904,\n",
              "  3686,\n",
              "  7253,\n",
              "  782,\n",
              "  18603,\n",
              "  197,\n",
              "  286,\n",
              "  633,\n",
              "  8799,\n",
              "  246],\n",
              " [3242,\n",
              "  4467,\n",
              "  4670,\n",
              "  531,\n",
              "  182,\n",
              "  3242,\n",
              "  4467,\n",
              "  857,\n",
              "  13905,\n",
              "  1777,\n",
              "  1242,\n",
              "  1092,\n",
              "  7255,\n",
              "  5501,\n",
              "  6239,\n",
              "  4671,\n",
              "  665,\n",
              "  858,\n",
              "  1320,\n",
              "  27,\n",
              "  9,\n",
              "  8,\n",
              "  531,\n",
              "  182,\n",
              "  508,\n",
              "  184,\n",
              "  13906,\n",
              "  8803,\n",
              "  633,\n",
              "  1162,\n",
              "  51,\n",
              "  141,\n",
              "  769,\n",
              "  1352,\n",
              "  1777,\n",
              "  1590,\n",
              "  3352,\n",
              "  783,\n",
              "  242,\n",
              "  2211,\n",
              "  47,\n",
              "  305,\n",
              "  13907,\n",
              "  403,\n",
              "  151,\n",
              "  2665,\n",
              "  13,\n",
              "  42,\n",
              "  27,\n",
              "  9,\n",
              "  214,\n",
              "  6240,\n",
              "  180,\n",
              "  110,\n",
              "  13908,\n",
              "  13909,\n",
              "  6241,\n",
              "  11597,\n",
              "  68,\n",
              "  240,\n",
              "  13910,\n",
              "  13911,\n",
              "  8804,\n",
              "  86,\n",
              "  107,\n",
              "  3830,\n",
              "  13912,\n",
              "  7933,\n",
              "  2125,\n",
              "  1242,\n",
              "  1830,\n",
              "  3243,\n",
              "  2965,\n",
              "  744,\n",
              "  566,\n",
              "  11598,\n",
              "  3242,\n",
              "  4467,\n",
              "  531,\n",
              "  182,\n",
              "  2740,\n",
              "  363,\n",
              "  11599,\n",
              "  666,\n",
              "  259,\n",
              "  527,\n",
              "  8,\n",
              "  47,\n",
              "  20,\n",
              "  156,\n",
              "  1831,\n",
              "  4912,\n",
              "  1777,\n",
              "  5201,\n",
              "  439,\n",
              "  518,\n",
              "  4672,\n",
              "  3242,\n",
              "  6242,\n",
              "  184,\n",
              "  13913,\n",
              "  9935,\n",
              "  666,\n",
              "  633,\n",
              "  13914,\n",
              "  13915,\n",
              "  484,\n",
              "  3244,\n",
              "  3353,\n",
              "  20,\n",
              "  1242,\n",
              "  2014,\n",
              "  9936,\n",
              "  6732,\n",
              "  1978,\n",
              "  3242,\n",
              "  6242,\n",
              "  1778,\n",
              "  4468,\n",
              "  105,\n",
              "  1566,\n",
              "  9937,\n",
              "  9937,\n",
              "  263,\n",
              "  1243,\n",
              "  131,\n",
              "  1777,\n",
              "  11600,\n",
              "  7255,\n",
              "  6239,\n",
              "  665,\n",
              "  1613,\n",
              "  9938,\n",
              "  856,\n",
              "  5202,\n",
              "  6733,\n",
              "  11601,\n",
              "  5203,\n",
              "  13916,\n",
              "  1064,\n",
              "  13917,\n",
              "  1654,\n",
              "  1705,\n",
              "  57,\n",
              "  1908,\n",
              "  354,\n",
              "  1,\n",
              "  3147,\n",
              "  13918,\n",
              "  232,\n",
              "  1937,\n",
              "  3045,\n",
              "  5827,\n",
              "  95,\n",
              "  8,\n",
              "  784,\n",
              "  249,\n",
              "  13919,\n",
              "  11602,\n",
              "  13920,\n",
              "  377,\n",
              "  1403,\n",
              "  1523,\n",
              "  12,\n",
              "  7256,\n",
              "  13921,\n",
              "  6243,\n",
              "  377,\n",
              "  8805,\n",
              "  939,\n",
              "  7,\n",
              "  572,\n",
              "  12,\n",
              "  2590,\n",
              "  1777,\n",
              "  13922,\n",
              "  11603]]"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ],
      "source": [
        "X = get_sequence_of_tokens(X)\n",
        "X[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "polish-malta",
      "metadata": {
        "id": "polish-malta"
      },
      "source": [
        "#### 6.Padding the Sequences\n",
        "\n",
        "Now that we have generated a data-set which contains sequence of tokens, it is possible that different sequences have different lengths. Before starting training the model, we need to pad the sequences and make their lengths equal. We can use pad_sequence function of Keras for this purpose."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rental-system",
      "metadata": {
        "id": "rental-system"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "def generate_padded_sequences(input_sequences, max_sequence = None):\n",
        "    if max_sequence is None:\n",
        "        max_sequence = max([len(x) for x in input_sequences])\n",
        "    input_sequences = pad_sequences(input_sequences, maxlen = max_sequence, padding = \"post\", truncating = \"post\")\n",
        "    \n",
        "    return input_sequences, max_sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "absolute-defendant",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "absolute-defendant",
        "outputId": "d18ff14d-d0ff-4f35-bc1f-80dca1075162"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  93,  173,  512, ...,    0,    0,    0],\n",
              "       [1490,  632,  299, ...,    0,    0,    0],\n",
              "       [2805, 6236, 3436, ...,    0,    0,    0],\n",
              "       [9928,  205, 1026, ...,    0,    0,    0],\n",
              "       [3242, 4467, 4670, ...,    0,    0,    0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ],
      "source": [
        "X, max_sequence = generate_padded_sequences(X)\n",
        "X[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "balanced-skirt",
      "metadata": {
        "id": "balanced-skirt"
      },
      "source": [
        "#### 7. Splitting the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "responsible-characteristic",
      "metadata": {
        "id": "responsible-characteristic"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "regular-hundred",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "regular-hundred",
        "outputId": "e5195970-d62d-4248-ba02-285590c801ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1780, 2219) (1780, 1)\n",
            "(445, 2219) (445, 1)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape, y_train.shape)\n",
        "print(X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "friendly-nursery",
      "metadata": {
        "id": "friendly-nursery"
      },
      "source": [
        "### 6.  LSTMs for Text Generation\n",
        "\n",
        "Unlike Feed-forward neural networks in which activation outputs are propagated only in one direction, the activation outputs from neurons propagate in both directions (from inputs to outputs and from outputs to inputs) in Recurrent Neural Networks. This creates loops in the neural network architecture which acts as a memory state of the neurons. This state allows the neurons an ability to remember what have been learned so far.\n",
        "\n",
        "The memory state in RNNs gives an advantage over traditional neural networks but a problem called Vanishing Gradient is associated with them. In this problem, while learning with a large number of layers, it becomes really hard for the network to learn and tune the parameters of the earlier layers. To address this problem, A new type of RNNs called LSTMs (Long Short Term Memory) Models have been developed.\n",
        "\n",
        "LSTMs have an additional state called cell state through which the network makes adjustments in the information flow. The advantage of this state is that the model can remember or forget the leanings more selectively. To learn more about LSTMs, here is a great post. Lets architecture a LSTM model in our code. I have added total three layers in the model.\n",
        "\n",
        "1. Input Layer : Takes the sequence of words as input\n",
        "2. LSTM Layer : Computes the output using LSTM units. I have added 100 units in the layer, but this number can be fine tuned later.\n",
        "3. Dropout Layer : A regularisation layer which randomly turns-off the activations of some neurons in the LSTM layer. It helps in preventing over fitting. (Optional Layer)\n",
        "4. Output Layer : Computes the probability of the best possible next word as output\n",
        "\n",
        "We will run this model for total 100 epoochs but it can be experimented further."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "administrative-somalia",
      "metadata": {
        "id": "administrative-somalia"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Embedding, SpatialDropout1D, LSTM, Dense, Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "def create_model(total_words, max_sequence):\n",
        "    \"\"\"\n",
        "    Generates a sparse matrix from ratings dataframe.\n",
        "    \n",
        "    Args:\n",
        "        df: pandas dataframe\n",
        "    \n",
        "    Returns:\n",
        "        X: sparse matrix\n",
        "        movie_mapper: dict that maps movie id's to movie indices\n",
        "    \"\"\"\n",
        "    \n",
        "    model = Sequential()\n",
        "    \n",
        "    # Add Input Embedding, Hidden and Ouput Layer\n",
        "    model.add(Embedding(input_dim = total_words, output_dim = 100, input_length = max_sequence))\n",
        "    model.add(SpatialDropout1D(0.2))\n",
        "    model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
        "    model.add(Dense(units = 5, activation='softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "   \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "daily-musical",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daily-musical",
        "outputId": "abf7975f-6075-4b52-a4bd-0792e17d6970"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, 2219, 100)         4377100   \n",
            "                                                                 \n",
            " spatial_dropout1d_3 (Spatia  (None, 2219, 100)        0         \n",
            " lDropout1D)                                                     \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 100)               80400     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 5)                 505       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,458,005\n",
            "Trainable params: 4,458,005\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = create_model(total_words, max_sequence)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "loved-surge",
      "metadata": {
        "id": "loved-surge"
      },
      "source": [
        "Let's train our model now"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "desperate-fellowship",
      "metadata": {
        "id": "desperate-fellowship"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train = to_categorical(y_train, 5)\n",
        "y_test = to_categorical(y_test, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "active-punch",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "active-punch",
        "outputId": "e9bae5fd-8131-4df2-a1af-30b9e0aac750"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1780, 2219)"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "billion-information",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "billion-information",
        "outputId": "c3c9b572-bd41-4d69-8ff3-48f168cf14eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "45/45 [==============================] - 426s 9s/step - loss: 1.6080 - accuracy: 0.2233 - val_loss: 1.6014 - val_accuracy: 0.2275\n",
            "Epoch 2/5\n",
            "18/45 [===========>..................] - ETA: 4:08 - loss: 1.6050 - accuracy: 0.2500"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-156-8053ff6a7fa8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_delta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model.fit(X_train, y_train, epochs = 5, batch_size = 32, validation_split=0.2, callbacks = [EarlyStopping(monitor='val_loss', patience=7, min_delta=0.0001)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "institutional-commodity",
      "metadata": {
        "id": "institutional-commodity"
      },
      "outputs": [],
      "source": [
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hydraulic-singles",
      "metadata": {
        "id": "hydraulic-singles"
      },
      "outputs": [],
      "source": [
        "model.save('model')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}